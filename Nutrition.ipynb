{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAWY6pZ2rBjG"
      },
      "source": [
        "\n",
        "\n",
        "*  Preprocesses the dataset,\n",
        "* Uses Label Encoding for categorical variables\n",
        "* Applies StandardScaler to numerical features\n",
        "* Splits the dataset into training & testing sets (80% train, 20% test)\n",
        "* Builds a simple ANN with 3 layers using ReLU activation\n",
        "* Uses Adam optimizer & Mean Squared Error (MSE) loss\n",
        "* Trains for 100 epochs with batch size 16\n",
        "* Saves the trained model for future predictions\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DDtI-57nq_vN"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "mtHEBW8JrVJ0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fvYGdrsNrn8m"
      },
      "outputs": [],
      "source": [
        "# Load dataset\n",
        "data = pd.read_csv(\"synthetic_diet_dataset.csv\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JjCQSbKGsQ8W"
      },
      "source": [
        "* Label Encoding is used to convert categorical values into numeric form for model compatibility.\n",
        "* Example: If \"Gender\" contains \"Male\" and \"Female\", it will be transformed into numbers like 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "xk3gpT0nsCdw"
      },
      "outputs": [],
      "source": [
        "# Encode categorical variables\n",
        "le_gender = LabelEncoder()\n",
        "le_goal = LabelEncoder()\n",
        "le_activity = LabelEncoder()\n",
        "le_diet_plan = LabelEncoder()\n",
        "le_food_items = LabelEncoder()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "0ZYjawKnvJTz"
      },
      "outputs": [],
      "source": [
        "# Apply Label Encoding to the relevant columns\n",
        "data['Gender'] = le_gender.fit_transform(data['Gender'])\n",
        "data['Goal'] = le_goal.fit_transform(data['Goal'])\n",
        "data['Activity_Level'] = le_activity.fit_transform(data['Activity_Level'])\n",
        "data['Diet_Plan'] = le_diet_plan.fit_transform(data['Diet_Plan'])\n",
        "data['Food_Items'] = le_food_items.fit_transform(data['Food_Items'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "25vlA8OIsIR9"
      },
      "outputs": [],
      "source": [
        "scaler = StandardScaler()\n",
        "data[[\"Weight\", \"Height\", \"Age\"]] = scaler.fit_transform(data[[\"Weight\", \"Height\", \"Age\"]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "x61-qIXCs5jk"
      },
      "outputs": [],
      "source": [
        "X = data[[\"Weight\", \"Height\", \"Age\", \"Gender\", \"Goal\", \"Activity_Level\"]]\n",
        "y = data[[\"Water_Intake(L)\", \"Protein_Intake(g)\", \"Diet_Plan\", \"Food_Items\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Hu2ke-1Us-To"
      },
      "outputs": [],
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kcek-WQuuJam",
        "outputId": "37dfd909-e78c-41aa-84fd-795bfdd6f750"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "# Build the ANN model\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\", input_shape=(X_train.shape[1],)),  # Input layer\n",
        "    tf.keras.layers.Dense(64, activation=\"relu\"),  # Hidden layer 1\n",
        "    tf.keras.layers.Dense(32, activation=\"relu\"),  # Hidden layer 2\n",
        "    tf.keras.layers.Dense(y_train.shape[1], activation=\"linear\")  # Output layer (4 values)\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "2CJ-qTWzuRTn"
      },
      "outputs": [],
      "source": [
        "#Compile the Model\n",
        "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\", metrics=[\"mse\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e1M5arykuVz9",
        "outputId": "ac548d4a-f857-4bdc-d3ee-2eb11f84ca08"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0494 - mse: 0.0494 - val_loss: 0.0499 - val_mse: 0.0499\n",
            "Epoch 2/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0462 - mse: 0.0462 - val_loss: 0.0474 - val_mse: 0.0474\n",
            "Epoch 3/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0457 - mse: 0.0457 - val_loss: 0.0598 - val_mse: 0.0598\n",
            "Epoch 4/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0655 - mse: 0.0655 - val_loss: 0.0478 - val_mse: 0.0478\n",
            "Epoch 5/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0442 - mse: 0.0442 - val_loss: 0.0455 - val_mse: 0.0455\n",
            "Epoch 6/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0508 - mse: 0.0508 - val_loss: 0.0483 - val_mse: 0.0483\n",
            "Epoch 7/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0557 - val_mse: 0.0557\n",
            "Epoch 8/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0483 - mse: 0.0483 - val_loss: 0.0483 - val_mse: 0.0483\n",
            "Epoch 9/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0428 - mse: 0.0428 - val_loss: 0.0473 - val_mse: 0.0473\n",
            "Epoch 10/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - loss: 0.0506 - mse: 0.0506 - val_loss: 0.0662 - val_mse: 0.0662\n",
            "Epoch 11/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.1018 - mse: 0.1018 - val_loss: 0.0748 - val_mse: 0.0748\n",
            "Epoch 12/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - loss: 0.0513 - mse: 0.0513 - val_loss: 0.0990 - val_mse: 0.0990\n",
            "Epoch 13/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0832 - mse: 0.0832 - val_loss: 0.0539 - val_mse: 0.0539\n",
            "Epoch 14/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0403 - val_mse: 0.0403\n",
            "Epoch 15/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0463 - mse: 0.0463 - val_loss: 0.0460 - val_mse: 0.0460\n",
            "Epoch 16/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0452 - mse: 0.0452 - val_loss: 0.0721 - val_mse: 0.0721\n",
            "Epoch 17/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0516 - mse: 0.0516 - val_loss: 0.0394 - val_mse: 0.0394\n",
            "Epoch 18/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0592 - val_mse: 0.0592\n",
            "Epoch 19/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0495 - mse: 0.0495 - val_loss: 0.0781 - val_mse: 0.0781\n",
            "Epoch 20/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0582 - mse: 0.0582 - val_loss: 0.0912 - val_mse: 0.0912\n",
            "Epoch 21/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0903 - mse: 0.0903 - val_loss: 0.0699 - val_mse: 0.0699\n",
            "Epoch 22/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0713 - mse: 0.0713 - val_loss: 0.0396 - val_mse: 0.0396\n",
            "Epoch 23/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0405 - mse: 0.0405 - val_loss: 0.0433 - val_mse: 0.0433\n",
            "Epoch 24/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0426 - mse: 0.0426 - val_loss: 0.0467 - val_mse: 0.0467\n",
            "Epoch 25/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0406 - mse: 0.0406 - val_loss: 0.0432 - val_mse: 0.0432\n",
            "Epoch 26/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0368 - mse: 0.0368 - val_loss: 0.0496 - val_mse: 0.0496\n",
            "Epoch 27/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0501 - mse: 0.0501 - val_loss: 0.0387 - val_mse: 0.0387\n",
            "Epoch 28/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0350 - mse: 0.0350 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 29/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0372 - mse: 0.0372 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 30/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0321 - mse: 0.0321 - val_loss: 0.0382 - val_mse: 0.0382\n",
            "Epoch 31/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0385 - mse: 0.0385 - val_loss: 0.0597 - val_mse: 0.0597\n",
            "Epoch 32/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0458 - mse: 0.0458 - val_loss: 0.0458 - val_mse: 0.0458\n",
            "Epoch 33/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0600 - mse: 0.0600 - val_loss: 0.0452 - val_mse: 0.0452\n",
            "Epoch 34/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0481 - val_mse: 0.0481\n",
            "Epoch 35/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0388 - val_mse: 0.0388\n",
            "Epoch 36/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0342 - mse: 0.0342 - val_loss: 0.0447 - val_mse: 0.0447\n",
            "Epoch 37/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0371 - mse: 0.0371 - val_loss: 0.0465 - val_mse: 0.0465\n",
            "Epoch 38/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0477 - mse: 0.0477 - val_loss: 0.0460 - val_mse: 0.0460\n",
            "Epoch 39/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0404 - mse: 0.0404 - val_loss: 0.0416 - val_mse: 0.0416\n",
            "Epoch 40/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0354 - mse: 0.0354 - val_loss: 0.0360 - val_mse: 0.0360\n",
            "Epoch 41/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0412 - mse: 0.0412 - val_loss: 0.0460 - val_mse: 0.0460\n",
            "Epoch 42/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0451 - mse: 0.0451 - val_loss: 0.0483 - val_mse: 0.0483\n",
            "Epoch 43/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0414 - mse: 0.0414 - val_loss: 0.0406 - val_mse: 0.0406\n",
            "Epoch 44/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0383 - mse: 0.0383 - val_loss: 0.0451 - val_mse: 0.0451\n",
            "Epoch 45/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0736 - mse: 0.0736 - val_loss: 0.0642 - val_mse: 0.0642\n",
            "Epoch 46/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1367 - mse: 0.1367 - val_loss: 0.1201 - val_mse: 0.1201\n",
            "Epoch 47/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.1098 - mse: 0.1098 - val_loss: 0.2429 - val_mse: 0.2429\n",
            "Epoch 48/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1449 - mse: 0.1449 - val_loss: 0.2060 - val_mse: 0.2060\n",
            "Epoch 49/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.1365 - mse: 0.1365 - val_loss: 0.0620 - val_mse: 0.0620\n",
            "Epoch 50/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0381 - mse: 0.0381 - val_loss: 0.0351 - val_mse: 0.0351\n",
            "Epoch 51/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0305 - mse: 0.0305 - val_loss: 0.0370 - val_mse: 0.0370\n",
            "Epoch 52/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0318 - mse: 0.0318 - val_loss: 0.0435 - val_mse: 0.0435\n",
            "Epoch 53/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step - loss: 0.0330 - mse: 0.0330 - val_loss: 0.0387 - val_mse: 0.0387\n",
            "Epoch 54/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0304 - mse: 0.0304 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 55/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0331 - mse: 0.0331 - val_loss: 0.0311 - val_mse: 0.0311\n",
            "Epoch 56/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0369 - mse: 0.0369 - val_loss: 0.0383 - val_mse: 0.0383\n",
            "Epoch 57/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0353 - mse: 0.0353 - val_loss: 0.0313 - val_mse: 0.0313\n",
            "Epoch 58/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0290 - mse: 0.0290 - val_loss: 0.0335 - val_mse: 0.0335\n",
            "Epoch 59/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0324 - mse: 0.0324 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 60/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0291 - mse: 0.0291 - val_loss: 0.0329 - val_mse: 0.0329\n",
            "Epoch 61/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0315 - mse: 0.0315 - val_loss: 0.0367 - val_mse: 0.0367\n",
            "Epoch 62/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0298 - mse: 0.0298 - val_loss: 0.0386 - val_mse: 0.0386\n",
            "Epoch 63/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0308 - mse: 0.0308 - val_loss: 0.0422 - val_mse: 0.0422\n",
            "Epoch 64/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0364 - mse: 0.0364 - val_loss: 0.0294 - val_mse: 0.0294\n",
            "Epoch 65/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0267 - mse: 0.0267 - val_loss: 0.0301 - val_mse: 0.0301\n",
            "Epoch 66/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0355 - mse: 0.0355 - val_loss: 0.0437 - val_mse: 0.0437\n",
            "Epoch 67/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0400 - mse: 0.0400 - val_loss: 0.0602 - val_mse: 0.0602\n",
            "Epoch 68/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.0636 - val_mse: 0.0636\n",
            "Epoch 69/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0512 - mse: 0.0512 - val_loss: 0.0332 - val_mse: 0.0332\n",
            "Epoch 70/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0327 - mse: 0.0327 - val_loss: 0.0601 - val_mse: 0.0601\n",
            "Epoch 71/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0409 - mse: 0.0409 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 72/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0343 - val_mse: 0.0343\n",
            "Epoch 73/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0360 - mse: 0.0360 - val_loss: 0.0289 - val_mse: 0.0289\n",
            "Epoch 74/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0322 - mse: 0.0322 - val_loss: 0.0353 - val_mse: 0.0353\n",
            "Epoch 75/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0336 - mse: 0.0336 - val_loss: 0.0369 - val_mse: 0.0369\n",
            "Epoch 76/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0351 - mse: 0.0351 - val_loss: 0.0457 - val_mse: 0.0457\n",
            "Epoch 77/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0450 - mse: 0.0450 - val_loss: 0.0519 - val_mse: 0.0519\n",
            "Epoch 78/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0370 - mse: 0.0370 - val_loss: 0.0369 - val_mse: 0.0369\n",
            "Epoch 79/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0379 - mse: 0.0379 - val_loss: 0.0355 - val_mse: 0.0355\n",
            "Epoch 80/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0320 - val_mse: 0.0320\n",
            "Epoch 81/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0325 - mse: 0.0325 - val_loss: 0.0321 - val_mse: 0.0321\n",
            "Epoch 82/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0376 - mse: 0.0376 - val_loss: 0.0486 - val_mse: 0.0486\n",
            "Epoch 83/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0418 - mse: 0.0418 - val_loss: 0.0380 - val_mse: 0.0380\n",
            "Epoch 84/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0402 - mse: 0.0402 - val_loss: 0.0341 - val_mse: 0.0341\n",
            "Epoch 85/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0317 - mse: 0.0317 - val_loss: 0.0352 - val_mse: 0.0352\n",
            "Epoch 86/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0319 - mse: 0.0319 - val_loss: 0.0404 - val_mse: 0.0404\n",
            "Epoch 87/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0301 - mse: 0.0301 - val_loss: 0.0421 - val_mse: 0.0421\n",
            "Epoch 88/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0440 - mse: 0.0440 - val_loss: 0.0546 - val_mse: 0.0546\n",
            "Epoch 89/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0333 - mse: 0.0333 - val_loss: 0.0287 - val_mse: 0.0287\n",
            "Epoch 90/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0265 - mse: 0.0265 - val_loss: 0.0309 - val_mse: 0.0309\n",
            "Epoch 91/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - loss: 0.0250 - mse: 0.0250 - val_loss: 0.0385 - val_mse: 0.0385\n",
            "Epoch 92/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - loss: 0.0277 - mse: 0.0277 - val_loss: 0.0276 - val_mse: 0.0276\n",
            "Epoch 93/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0270 - mse: 0.0270 - val_loss: 0.0292 - val_mse: 0.0292\n",
            "Epoch 94/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - loss: 0.0312 - mse: 0.0312 - val_loss: 0.0671 - val_mse: 0.0671\n",
            "Epoch 95/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 6ms/step - loss: 0.0603 - mse: 0.0603 - val_loss: 0.1034 - val_mse: 0.1034\n",
            "Epoch 96/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0688 - mse: 0.0688 - val_loss: 0.1292 - val_mse: 0.1292\n",
            "Epoch 97/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - loss: 0.0679 - mse: 0.0679 - val_loss: 0.0510 - val_mse: 0.0510\n",
            "Epoch 98/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0408 - mse: 0.0408 - val_loss: 0.0304 - val_mse: 0.0304\n",
            "Epoch 99/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0410 - val_mse: 0.0410\n",
            "Epoch 100/100\n",
            "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.0309 - mse: 0.0309 - val_loss: 0.0435 - val_mse: 0.0435\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7fbc75f4b590>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=16, validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lpgku-wWux0g",
        "outputId": "832fdc62-abbb-4e6a-a454-0bec69878a0e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model\n",
        "y_pred = model.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "OXlPz5_avO4h"
      },
      "outputs": [],
      "source": [
        "# Calculate performance metrics\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "mae = mean_absolute_error(y_test, y_pred)\n",
        "r2 = r2_score(y_test, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QbvxSAeOvuKz",
        "outputId": "b19d305c-a9a9-4946-8d3d-9ecc7e0a2b67"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mean Squared Error (MSE): 0.0435\n",
            "Mean Absolute Error (MAE): 0.1608\n",
            "R² Score: 0.9489\n"
          ]
        }
      ],
      "source": [
        "print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
        "print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
        "print(f\"R² Score: {r2:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OvfhbX16v7FR",
        "outputId": "16d07026-c80b-429e-ea1f-9d0096542c2c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model training completed and saved as 'data_model.h5'\n"
          ]
        }
      ],
      "source": [
        "# Save the trained model\n",
        "model.save(\"data_model.h5\")\n",
        "print(\"Model training completed and saved as 'data_model.h5'\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13zPfYlKwL4b"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
